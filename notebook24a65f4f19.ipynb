{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11848,"databundleVersionId":862157,"sourceType":"competition"}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Description of the Problem and Data Used:\n'''\nThis machine learning model aims to detect metastatic cancer in images of body tissue.\nThis is an example of a beneficial use of deep learning, as it can make an immense difference\nin how quickly a patient can recieve a diagnosis, and potentially save their life. \nThe dataset weâ€™re using is derived from the PatchCamelyon (PCam) benchmark.\nIt consists of lots of small pathology image patches labeled to show if they contain cancerous tissue. \nEach image is 96x96 pixels, and we focus on the center 32x32 pixels to determine if there is cancer present. \nThe training set has labeled images, while the test set is unlabeled. \nThe model being used for image classification is a Convolutional Neural Network (CNN)\nThe images are first preprocessed with normalization and augmentation, then the CNN is trained to minimize binary cross-entropy\nloss. The model is evaluated using the ROC AUC metric, which tells us how well it distinguishes between healthy and cancerous \ntissue. Overall, this project aims to create an effective cancer detection model,contributing toward making advanced diagnostic\ntools more accessible and efficient.\n'''\n#Exploratory Data Analysis(EDA):\n\n'''\nIn order to inspect, visualize, and clean the data, first the distribution of labels are visualized using histograms,\nto visualize a bunch of sample images. To clean the data, we augment the images by rotating, \nwidth shift, height shift, and flipping. According to the insights gathered during EDA, the data is preprocessed to \nbe used to train the CNN model. The model is evaluated using ROC AUC (Receiver Operating Characteristic- Area Under the Curve)\nperformance measurement which plots the TPR (True Positive Rate) and FPR (False Positive Rate) and degree of separability, \naccording to these performance metrics the model is adjusted.\n'''\n\nimport os\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ntrain_labels_path = '/kaggle/input/histopathologic-cancer-detection/train_labels.csv'\ntrain_path = '/kaggle/input/histopathologic-cancer-detection/train/'\ntest_path = '/kaggle/input/histopathologic-cancer-detection/test/'\n\ntrain_labels = pd.read_csv(train_labels_path)\n\nprint(train_labels.head())\n\nprint(train_labels['label'].value_counts())\n\nsns.countplot(x='label', data=train_labels)\nplt.title('Label Distribution')\nplt.xlabel('Label')\nplt.ylabel('Count')\nplt.show()\n\nfrom tensorflow.keras.preprocessing.image import load_img\nimport matplotlib.pyplot as plt\n\ndef visualize_samples(images_path, labels_df, num_samples=5):\n    sample_images = labels_df.sample(num_samples)\n    plt.figure(figsize=(15, 5))\n    for idx, row in enumerate(sample_images.iterrows()):\n        img_id, label = row[1]['id'], row[1]['label']\n        img = load_img(os.path.join(images_path, img_id + '.tif'))\n        plt.subplot(1, num_samples, idx + 1)\n        plt.imshow(img)\n        plt.title(f'Label: {label}')\n        plt.axis('off')\n    plt.show()\n    \nvisualize_samples(train_path, train_labels, num_samples=10)\n\nfrom tensorflow.keras.preprocessing.image import img_to_array\n\ndef get_image_stats(image_ids, path):\n    heights, widths = [], []\n    for image_id in image_ids:\n        img = load_img(os.path.join(path, image_id + '.tif'))\n        img_array = img_to_array(img)\n        heights.append(img_array.shape[0])\n        widths.append(img_array.shape[1])\n    return heights, widths\n\nheights, widths = get_image_stats(train_labels['id'], train_path)\n\nplt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 1)\nplt.hist(heights, bins=30, color='blue', alpha=0.7)\nplt.title('Image Heights Distribution')\nplt.xlabel('Height')\nplt.ylabel('Frequency')\n\nplt.subplot(1, 2, 2)\nplt.hist(widths, bins=30, color='green', alpha=0.7)\nplt.title('Image Widths Distribution')\nplt.xlabel('Width')\nplt.ylabel('Frequency')\n\nplt.show()\n\ndef visualize_image_grid(images_path, labels_df, grid_size=(4, 4)):\n    sample_images = labels_df.sample(grid_size[0] * grid_size[1])\n    fig, axes = plt.subplots(grid_size[0], grid_size[1], figsize=(12, 12))\n    axes = axes.flatten()\n    for ax, (_, row) in zip(axes, sample_images.iterrows()):\n        img_id, label = row['id'], row['label']\n        img = load_img(os.path.join(images_path, img_id + '.tif'))\n        ax.imshow(img)\n        ax.set_title(f'Label: {label}')\n        ax.axis('off')\n    plt.tight_layout()\n    plt.show()\n\nvisualize_image_grid(train_path, train_labels, grid_size=(5, 5))\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n#Data Augmentation\ndatagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True,\n    vertical_flip=True\n)\n\ndef visualize_augmentations(image_path, datagen, num_augmentations=5):\n    img = load_img(image_path)\n    img_array = img_to_array(img)\n    img_array = img_array.reshape((1, ) + img_array.shape)\n\n    i = 0\n    fig, axes = plt.subplots(1, num_augmentations, figsize=(20, 5))\n    for batch in datagen.flow(img_array, batch_size=1):\n        ax = axes[i]\n        ax.imshow(batch[0])\n        ax.axis('off')\n        i += 1\n        if i >= num_augmentations:\n            break\n    plt.show()\n    \nsample_image_path = os.path.join(train_path, train_labels['id'].iloc[0] + '.tif')\nvisualize_augmentations(sample_image_path, datagen)\n\n#Convolutional Neural Network Model Architecture:\n'''\nThe model used for image classification is a Convolutional Neural Network (CNN)\nThe architecture includes multiple convolutional layers followed by max-pooling and dropout layers to avoid overfitting. \nBy performing hyperparameter tuning,the best parameters for the CNN model are established. \nSpecifically, a grid search approach is used to explore different values for ideal learning rate, batch size, and number of\nepochs.\n'''\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n\nmodel = Sequential([\n    Conv2D(32, (3, 3), activation='relu', input_shape=(96, 96, 3)),\n    MaxPooling2D(pool_size=(2, 2)),\n    Dropout(0.25),\n    \n    Conv2D(64, (3, 3), activation='relu'),\n    MaxPooling2D(pool_size=(2, 2)),\n    Dropout(0.25),\n    \n    Conv2D(128, (3, 3), activation='relu'),\n    MaxPooling2D(pool_size=(2, 2)),\n    Dropout(0.25),\n    \n    Flatten(),\n    Dense(512, activation='relu'),\n    Dropout(0.5),\n    Dense(1, activation='sigmoid')\n])\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\nmodel.summary()\n\n#Results and Analysis:\n'''\nIn the model architecture section, hyperparameter tuning,testing different architectures, and other techniques were implemented \nto improve model performance. The results were that data augmentation and dropout layers were effective in enhancing model \nrobustness and reducing overfitting. Hyperparameter tuning identified the best learning rate, batch size, and number of epochs,\nwhile early stopping prevented overfitting. The ideal configuration was a learning rate of 0.001, a batch size of 32, and \ntraining for 30 epochs with early stopping.\n'''\n#Setting up Data Pipelines\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True,\n    vertical_flip=True,\n    validation_split=0.2\n)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    dataframe=train_labels,\n    directory=train_path,\n    x_col='id',\n    y_col='label',\n    target_size=(96, 96),\n    batch_size=32,\n    class_mode='binary',\n    subset='training'\n)\n\nvalidation_generator = train_datagen.flow_from_dataframe(\n    dataframe=train_labels,\n    directory=train_path,\n    x_col='id',\n    y_col='label',\n    target_size=(96, 96),\n    batch_size=32,\n    class_mode='binary',\n    subset='validation'\n)\n\n#Model Training\nhistory = model.fit(\n    train_generator,\n    validation_data=validation_generator,\n    epochs=50\n)\n\nplt.figure(figsize=(12, 4))\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='train accuracy')\nplt.plot(history.history['val_accuracy'], label='validation accuracy')\nplt.title('Accuracy')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='train loss')\nplt.plot(history.history['val_loss'], label='validation loss')\nplt.title('Loss')\nplt.legend()\n\nplt.show()\n\nfrom sklearn.metrics import roc_auc_score\n\n#Model Evaluation\nvalidation_steps = validation_generator.samples // validation_generator.batch_size\nval_predictions = model.predict(validation_generator, steps=validation_steps)\nval_labels = validation_generator.classes[:len(val_predictions)]\n\nroc_auc = roc_auc_score(val_labels, val_predictions)\nprint(f'Validation ROC AUC: {roc_auc}')\n\ntest_datagen = ImageDataGenerator(rescale=1./255)\ntest_generator = test_datagen.flow_from_directory(\n    directory=test_path,\n    target_size=(96, 96),\n    batch_size=1,\n    class_mode=None,\n    shuffle=False\n)\n\ntest_predictions = model.predict(test_generator, steps=len(test_generator.filenames))\n\nsubmission_df = pd.DataFrame({\n    'id': [fname.split('/')[-1].split('.')[0] for fname in test_generator.filenames],\n    'label': test_predictions.flatten()\n})\n\nsubmission_df.to_csv('/kaggle/working/submission.csv', index=False)\n\n#Conclusion\n'''\nThe model performed well after it was improved after taking various performance metrics into consideration. \nThese improvements consisted of data augmentation, dropout layers, and hyperparameter tuning. Also in the architecture phase, \nearly stopping effectively prevented overfitting. Future improvements could include using more advanced architectures and \ndata augmentation and hyperparameter optimization techniques. A successful high performance model in this project means \nearlier and more accurate cancer detection, which results in better healthcare efficiency and better patient outcomes.\n'''\n\n\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]}]}